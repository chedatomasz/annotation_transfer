{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "def records(path):\n",
    "    records = list(SeqIO.parse(path, \"fasta\"))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_from_gopredsim_annotation(pth):\n",
    "    with open(pth, 'r') as opened:\n",
    "        ids = set(x.split()[0] for x in opened.readlines())\n",
    "        print(len(ids))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine the sets of train and test ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the training set originally provided in the CAFA3 challenge, although use could also use other information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66841"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_cafa3_file = \"uniprot_sprot_exp.fasta\"\n",
    "orig_cafa3_ids_set = set(str(x.id) for x in records(orig_cafa3_file))\n",
    "len(orig_cafa3_ids_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the training set prepared by goPredSim developers,\n",
    "closely matching the CAFA3 set, with a corresponding temporal cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68038\n"
     ]
    }
   ],
   "source": [
    "gopredsim_file = \"goa_annotations_exp_2017.txt\"\n",
    "gopredsim_ids_set = ids_from_gopredsim_annotation(gopredsim_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take their intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = orig_cafa3_ids_set.intersection(gopredsim_ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62626"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test set, we take the set of proteins which got new annotations in the CAFA3 review period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = set(str(x.id) for x in records(\"cafa3_targets.fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3328"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the sets of embeddings in format required by goPredSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_folder = \"prepared_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def get_dict_from_separate_files(embeddings_file, ids_file):\n",
    "    embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "    ids = np.load(ids_file, allow_pickle=True)\n",
    "    embed_dict = {id_: em for id_, em in zip(ids, embeddings)}\n",
    "    return embed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(source, ids, allow_missing=False):\n",
    "    res = dict()\n",
    "    for i in ids:\n",
    "        try:\n",
    "            res[i]=source[i]\n",
    "        except KeyError as e:\n",
    "            print(f\"missing embedding for {i}\")\n",
    "            if not allow_missing:\n",
    "                raise e\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_dict(di, name):\n",
    "    with open(f\"{name}.pkl\", 'wb') as fp:\n",
    "        pickle.dump(di, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_separate(model, split):\n",
    "    assert split in (\"train\", \"test\")\n",
    "    model_data_ids = os.path.join(embeddings_folder, f\"{model}_{split}_ids.npy\")\n",
    "    model_data_ems = os.path.join(embeddings_folder, f\"{model}_{split}_embeddings.npy\")\n",
    "    model_data_full = get_dict_from_separate_files(model_data_ems, model_data_ids)\n",
    "    ids = train_ids if split == \"train\" else test_ids\n",
    "    model_data = get_subset(model_data_full, ids)\n",
    "    save_dict(model_data, f\"{model}.{split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# Code based on that of goPredSim\n",
    "def read_h5_embeddings(embeddings_in):\n",
    "    \"\"\"A2ASS6\n",
    "    Read embeddings from h5 file generated by bio_embeddings pipeline\n",
    "    :param embeddings_in: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    embeddings = dict()\n",
    "    with h5py.File(embeddings_in, 'r') as f:\n",
    "        for key, embedding in tqdm.tqdm(f.items()):\n",
    "            original_id = embedding.attrs['original_id']\n",
    "            embeddings[original_id] = np.array(embedding)\n",
    "            \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_from_h5(model, split, allow_missing=False):\n",
    "    assert split in (\"train\", \"test\")\n",
    "    if split==\"train\":\n",
    "        data_path = os.path.join(embeddings_folder, f\"{model}_goa_2017.h5\")\n",
    "    else:\n",
    "        data_path = os.path.join(embeddings_folder, f\"{model}_cafa3_targets.h5\")\n",
    "        \n",
    "    model_data_full = read_h5_embeddings(data_path)\n",
    "    ids = train_ids if split == \"train\" else test_ids\n",
    "    model_data = get_subset(model_data_full, ids, allow_missing=allow_missing)\n",
    "    save_dict(model_data, f\"{model}.{split}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proteinbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_separate(\"proteinbert\", \"train\")\n",
    "prepare_separate(\"proteinbert\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "protbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_separate(\"protbert\", \"train\")\n",
    "prepare_separate(\"protbert\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def esm2_filter(file):\n",
    "    with open(file, 'rb') as opened:\n",
    "        di = pickle.load(opened)\n",
    "    out = {i: o[33] for i, o in di.items()}\n",
    "    with open(file, 'wb') as fp:\n",
    "        pickle.dump(out, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prepare_separate(\"esm2\", \"train\")\n",
    "prepare_separate(\"esm2\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def esm2_filter2(file):\n",
    "    with open(file, 'rb') as opened:\n",
    "        di = pickle.load(opened)\n",
    "    out = {i: o.numpy() for i, o in di.items()}\n",
    "    with open(file, 'wb') as fp:\n",
    "        pickle.dump(out, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2_filter(\"esm2.train.pkl\")\n",
    "esm2_filter(\"esm2.test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm2_filter2(\"esm2.train.pkl\")\n",
    "esm2_filter2(\"esm2.test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prott5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307278/307278 [01:27<00:00, 3501.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing embedding for A2ASS6\n",
      "missing embedding for G4SLH0\n",
      "missing embedding for Q9I7U4\n",
      "missing embedding for Q8WZ42\n",
      "missing embedding for Q8WXI7\n",
      "missing embedding for Q09165\n"
     ]
    }
   ],
   "source": [
    "prepare_from_h5(\"prott5\", \"train\", allow_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3328/3328 [00:00<00:00, 3546.41it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_from_h5(\"prott5\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seqvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307278/307278 [01:32<00:00, 3330.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing embedding for A2ASS6\n",
      "missing embedding for G4SLH0\n",
      "missing embedding for Q9I7U4\n",
      "missing embedding for Q8WZ42\n",
      "missing embedding for Q8WXI7\n",
      "missing embedding for Q09165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3328/3328 [00:01<00:00, 2725.63it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_from_h5(\"seqvec\", \"train\", allow_missing=True)\n",
    "prepare_from_h5(\"seqvec\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preexisting protbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 307278/307278 [01:35<00:00, 3212.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing embedding for Q09165\n",
      "missing embedding for Q9I7U4\n",
      "missing embedding for Q8WZ42\n",
      "missing embedding for G4SLH0\n",
      "missing embedding for A2ASS6\n",
      "missing embedding for Q8WXI7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3328/3328 [00:01<00:00, 3231.66it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_from_h5(\"theirprotbert\", \"train\", allow_missing=True)\n",
    "prepare_from_h5(\"theirprotbert\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    with open(file, 'rb') as opened:\n",
    "        di = pickle.load(opened)\n",
    "        return di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(load(\"project/theirprotbert.test.pkl\").values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(load(\"project/protbert.test.pkl\").values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the set of annotations for our train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_annotations(annotations_file, id_set, output_file):\n",
    "    with open(annotations_file, 'r') as in_file:\n",
    "        with open(output_file, 'w') as out_file:\n",
    "            for line in in_file.readlines():\n",
    "                line_id = line.split()[0]\n",
    "                if line_id in id_set:\n",
    "                    print(line, file=out_file, end='') #line already has newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_annotations(\"goa_annotations_exp_2017.txt\", train_ids, \"project_annotations.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_configs():\n",
    "    #os.mkdir(\"configs\")\n",
    "    for model in (\"theirprotbert\",):#\"prott5\", \"seqvec\", \"esm2\", \"protbert\", \"proteinbert\":\n",
    "        with open(os.path.join(\"configs\", f\"{model}_config.txt\"), 'w') as config_file:\n",
    "            print(\"go: data/GO/go_cafa3.obo\", file=config_file)\n",
    "            print(f\"lookup_set: project/{model}.train.pkl\", file=config_file)\n",
    "            print(f\"annotations: project_annotations.txt\", file= config_file)\n",
    "            print(f\"targets: project/{model}.test.pkl\", file=config_file)\n",
    "            print(f\"onto: all\", file=config_file)\n",
    "            print(f\"thresh: 1\", file=config_file)\n",
    "            print(f\"modus: num\", file=config_file)\n",
    "            print(f\"output: results/{model}\", file=config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_configs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_assess():\n",
    "    #os.mkdir(\"assess_configs\")\n",
    "    for model in (\"theirprotbert\",):#\"prott5\", \"seqvec\", \"esm2\", \"protbert\", \"proteinbert\":\n",
    "        for onto in \"BPO\", \"MFO\", \"CCO\": \n",
    "            d = {\n",
    "                \"file\" : f\"predictions/{model}-Tch_1_all_go_{onto}.txt\",\n",
    "                \"obo\": \"./precrec/go_cafa3.obo\",\n",
    "                \"benchmark\": \"./precrec/benchmark/CAFA3_benchmarks/\",\n",
    "                \"results\": \"./results\"\n",
    "            }\n",
    "            conf = yaml.dump({\"assess\": d, \"plot\": {}})\n",
    "            with open(f\"assess_configs/{model}_{onto}.yaml\", 'w') as opened:\n",
    "                print(conf, file=opened, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "produce_assess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fmax DataFrame:\n",
      "benchmark_type             NK        LK        NK        LK        NK  \\\n",
      "ontology                  BPO       BPO       CCO       CCO       MFO   \n",
      "model                                                                   \n",
      "files/esm2           0.320937  0.340213  0.575237  0.570138  0.504384   \n",
      "files/protbert       0.260052  0.315406  0.538194  0.537135  0.398696   \n",
      "files/proteinbert    0.311029  0.362275  0.571419  0.543442  0.511744   \n",
      "files/prott5         0.324303  0.331968  0.588554  0.566115  0.531228   \n",
      "files/seqvec         0.305571  0.292032  0.561114  0.540299  0.496337   \n",
      "files/theirprotbert  0.297858  0.330947  0.567013  0.538607  0.472835   \n",
      "\n",
      "benchmark_type             LK  \n",
      "ontology                  MFO  \n",
      "model                          \n",
      "files/esm2           0.441647  \n",
      "files/protbert       0.348051  \n",
      "files/proteinbert    0.451957  \n",
      "files/prott5         0.462393  \n",
      "files/seqvec         0.421948  \n",
      "files/theirprotbert  0.431698  \n",
      "\n",
      "Threshold DataFrame:\n",
      "benchmark_type         NK    LK    NK    LK    NK    LK\n",
      "ontology              BPO   BPO   CCO   CCO   MFO   MFO\n",
      "model                                                  \n",
      "files/esm2           0.19  0.20  0.13  0.20  0.21  0.14\n",
      "files/protbert       0.28  0.16  0.21  0.21  0.11  0.12\n",
      "files/proteinbert    0.09  0.07  0.07  0.06  0.04  0.05\n",
      "files/prott5         0.30  0.30  0.19  0.30  0.19  0.18\n",
      "files/seqvec         0.32  0.38  0.25  0.29  0.28  0.22\n",
      "files/theirprotbert  0.35  0.32  0.28  0.34  0.25  0.13\n"
     ]
    }
   ],
   "source": [
    "#this cell has been created with chatgpt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_result_file(file_path):\n",
    "    result_data = {}\n",
    "    ontology_matched = False\n",
    "    model = file_path.split(\"_\")[1]\n",
    "    ontology = file_path.split(\"_\")[-1].split(\".\")[0].upper()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    mode = None\n",
    "    benchmark_type = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"ontology:\"):\n",
    "            current_ontology = line.split(\":\")[1].strip().upper()\n",
    "            if current_ontology == ontology:\n",
    "                ontology_matched = True\n",
    "            else:\n",
    "                ontology_matched = False\n",
    "        elif ontology_matched:\n",
    "            if line.startswith(\"mode:\"):\n",
    "                mode = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"benchmark type:\"):\n",
    "                benchmark_type = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"fmax:\") and mode == \"full\":\n",
    "                fmax = float(line.split(\":\")[1].strip())\n",
    "                key = (benchmark_type, ontology, model)\n",
    "                result_data.setdefault(key, {})['fmax'] = fmax\n",
    "            elif line.startswith(\"threshold giving fmax:\") and mode == \"full\":\n",
    "                threshold = float(line.split(\":\")[1].strip())\n",
    "                key = (benchmark_type, ontology, model)\n",
    "                result_data.setdefault(key, {})['threshold'] = threshold\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "# Iterate over all files in the output directory\n",
    "output_dir = \"output_files\"\n",
    "fmax_results = []\n",
    "threshold_results = []\n",
    "\n",
    "for file_name in os.listdir(output_dir):\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Parse the result file\n",
    "    result_data = parse_result_file(file_path)\n",
    "\n",
    "    # Store the extracted data in a list of dictionaries\n",
    "    if result_data:\n",
    "        fmaxes = {key: data['fmax'] for key, data in result_data.items() if 'threshold' in data}\n",
    "        fmax_results.extend(fmaxes.items())\n",
    "\n",
    "        # Extract the threshold data\n",
    "        thresholds = {key: data['threshold'] for key, data in result_data.items() if 'threshold' in data}\n",
    "        threshold_results.extend(thresholds.items())\n",
    "\n",
    "# Create a DataFrame for fmax values\n",
    "fmax_df = pd.DataFrame(fmax_results, columns=['benchmark_type_ontology_model', 'results'])\n",
    "fmax_df[['benchmark_type', 'ontology', 'model']] = pd.DataFrame(fmax_df['benchmark_type_ontology_model'].tolist(), index=fmax_df.index)\n",
    "fmax_df = fmax_df.drop('benchmark_type_ontology_model', axis=1)\n",
    "\n",
    "# Pivot the fmax DataFrame\n",
    "fmax_pivot = fmax_df.pivot(index='model', columns=['benchmark_type', 'ontology'], values='results')\n",
    "\n",
    "# Create a DataFrame for thresholds\n",
    "threshold_df = pd.DataFrame(threshold_results, columns=['benchmark_type_ontology_model', 'threshold'])\n",
    "threshold_df[['benchmark_type', 'ontology', 'model']] = pd.DataFrame(threshold_df['benchmark_type_ontology_model'].tolist(), index=threshold_df.index)\n",
    "threshold_df = threshold_df.drop('benchmark_type_ontology_model', axis=1)\n",
    "\n",
    "# Pivot the threshold DataFrame\n",
    "threshold_pivot = threshold_df.pivot(index='model', columns=['benchmark_type', 'ontology'], values='threshold')\n",
    "\n",
    "# Print the fmax DataFrame\n",
    "print(\"Fmax DataFrame:\")\n",
    "print(fmax_pivot)\n",
    "\n",
    "# Print the threshold DataFrame\n",
    "print(\"\\nThreshold DataFrame:\")\n",
    "print(threshold_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NK', 'BPO', 'output'), 0.3191653498509426),\n",
       " (('LK', 'BPO', 'output'), 0.3431828174196418),\n",
       " (('NK', 'CCO', 'output'), 0.5839474233111744),\n",
       " (('LK', 'CCO', 'output'), 0.56327549723111),\n",
       " (('NK', 'MFO', 'output'), 0.5108162370889814),\n",
       " (('LK', 'MFO', 'output'), 0.4546069655838999),\n",
       " (('NK', 'BPO', 'output'), 0.26406124274401904),\n",
       " (('LK', 'BPO', 'output'), 0.3145956336279498),\n",
       " (('NK', 'CCO', 'output'), 0.5372396511878191),\n",
       " (('LK', 'CCO', 'output'), 0.5343917945928709),\n",
       " (('NK', 'MFO', 'output'), 0.3979736574652955),\n",
       " (('LK', 'MFO', 'output'), 0.3507041730403241),\n",
       " (('NK', 'BPO', 'output'), 0.3089987882973226),\n",
       " (('LK', 'BPO', 'output'), 0.36730118795227124),\n",
       " (('NK', 'CCO', 'output'), 0.5729976347154231),\n",
       " (('LK', 'CCO', 'output'), 0.5362689622488322),\n",
       " (('NK', 'MFO', 'output'), 0.52246873663165),\n",
       " (('LK', 'MFO', 'output'), 0.4449159105223092),\n",
       " (('NK', 'BPO', 'output'), 0.3219275394528631),\n",
       " (('LK', 'BPO', 'output'), 0.3328045729998566),\n",
       " (('NK', 'CCO', 'output'), 0.5861962463960505),\n",
       " (('LK', 'CCO', 'output'), 0.5629856555171122),\n",
       " (('NK', 'MFO', 'output'), 0.5412286110334799),\n",
       " (('LK', 'MFO', 'output'), 0.45701779634416206),\n",
       " (('NK', 'BPO', 'output'), 0.31194621384746163),\n",
       " (('LK', 'BPO', 'output'), 0.2983453828330413),\n",
       " (('NK', 'CCO', 'output'), 0.5581434988264784),\n",
       " (('LK', 'CCO', 'output'), 0.5325684029490236),\n",
       " (('NK', 'MFO', 'output'), 0.5212109304804815),\n",
       " (('LK', 'MFO', 'output'), 0.42859324370839386),\n",
       " (('NK', 'BPO', 'output'), 0.2976306478121041),\n",
       " (('LK', 'BPO', 'output'), 0.3291509340108948),\n",
       " (('NK', 'CCO', 'output'), 0.5618506503110158),\n",
       " (('LK', 'CCO', 'output'), 0.5452266244063264),\n",
       " (('NK', 'MFO', 'output'), 0.47057285144778477),\n",
       " (('LK', 'MFO', 'output'), 0.41830417718269286)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this cell has been created with chatgpt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def parse_result_file(file_path):\n",
    "    result_data = {}\n",
    "    ontology_matched = False\n",
    "    model = file_path.split(\"_\")[1]\n",
    "    ontology = file_path.split(\"_\")[-1].split(\".\")[0].upper()\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    mode = None\n",
    "    benchmark_type = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"ontology:\"):\n",
    "            current_ontology = line.split(\":\")[1].strip().upper()\n",
    "            if current_ontology == ontology:\n",
    "                ontology_matched = True\n",
    "            else:\n",
    "                ontology_matched = False\n",
    "        elif ontology_matched:\n",
    "            if line.startswith(\"mode:\"):\n",
    "                mode = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"benchmark type:\"):\n",
    "                benchmark_type = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"fmax:\") and mode == \"full\":\n",
    "                fmax = float(line.split(\":\")[1].strip())\n",
    "                key = (benchmark_type, ontology, model)\n",
    "                result_data.setdefault(key, {})['fmax'] = fmax\n",
    "            elif line.startswith(\"threshold giving fmax:\") and mode == \"full\":\n",
    "                threshold = float(line.split(\":\")[1].strip())\n",
    "                key = (benchmark_type, ontology, model)\n",
    "                result_data.setdefault(key, {})['threshold'] = threshold\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "# Iterate over all files in the output directory\n",
    "output_dir = \"assessment-output-cosine\"\n",
    "fmax_results = []\n",
    "threshold_results = []\n",
    "\n",
    "for file_name in os.listdir(output_dir):\n",
    "    file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    # Parse the result file\n",
    "    result_data = parse_result_file(file_path)\n",
    "\n",
    "    # Store the extracted data in a list of dictionaries\n",
    "    if result_data:\n",
    "        fmaxes = {key: data['fmax'] for key, data in result_data.items() if 'threshold' in data}\n",
    "        fmax_results.extend(fmaxes.items())\n",
    "\n",
    "        # Extract the threshold data\n",
    "        thresholds = {key: data['threshold'] for key, data in result_data.items() if 'threshold' in data}\n",
    "        threshold_results.extend(thresholds.items())\n",
    "\n",
    "fmax_results\n",
    "# # Create a DataFrame for fmax values\n",
    "# fmax_df = pd.DataFrame(fmax_results, columns=['benchmark_type_ontology_model', 'results'])\n",
    "# fmax_df[['benchmark_type', 'ontology', 'model']] = pd.DataFrame(fmax_df['benchmark_type_ontology_model'].tolist(), index=fmax_df.index)\n",
    "# fmax_df = fmax_df.drop('benchmark_type_ontology_model', axis=1)\n",
    "\n",
    "# # Pivot the fmax DataFrame\n",
    "# fmax_pivot = fmax_df.pivot(index='model', columns=['benchmark_type', 'ontology'], values='results')\n",
    "\n",
    "# # Create a DataFrame for thresholds\n",
    "# threshold_df = pd.DataFrame(threshold_results, columns=['benchmark_type_ontology_model', 'threshold'])\n",
    "# threshold_df[['benchmark_type', 'ontology', 'model']] = pd.DataFrame(threshold_df['benchmark_type_ontology_model'].tolist(), index=threshold_df.index)\n",
    "# threshold_df = threshold_df.drop('benchmark_type_ontology_model', axis=1)\n",
    "\n",
    "# # Pivot the threshold DataFrame\n",
    "# threshold_pivot = threshold_df.pivot(index='model', columns=['benchmark_type', 'ontology'], values='threshold')\n",
    "\n",
    "# # Print the fmax DataFrame\n",
    "# print(\"Fmax DataFrame:\")\n",
    "# print(fmax_pivot)\n",
    "\n",
    "# # Print the threshold DataFrame\n",
    "# print(\"\\nThreshold DataFrame:\")\n",
    "# print(threshold_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
